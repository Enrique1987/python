{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f65fef8",
   "metadata": {},
   "source": [
    "## Summarizing customer Feedback with NLP: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759f8b1e",
   "metadata": {},
   "source": [
    "In this notebook we will use the NLTK to geneare a summary the customer Feedback from call center.\n",
    "\n",
    "In these data mining process we will use a extraction approach.\n",
    "\n",
    "`Extraction-based:`  Uses various weighting functions to rank sentences by perceveived importance. Words uses more often are considered more important. Consequently, sentences containing those words are considred more important. The overall behavior is like using a yellow highligther to manually select keywords and sentences without altering the text.\n",
    "\n",
    "This technique is good at pulling out important words and phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4e666d",
   "metadata": {},
   "source": [
    "#### Pipeline\n",
    "\n",
    "   1. Tokenizes the text into words and sentences\n",
    "   2. Removes stop words with no contextual content\n",
    "   3. Counts the remaining words\n",
    "   4. Uses the counts to rank the sentences \n",
    "   5. Displays the highest-ranking sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10536d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import bs4\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbfff892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(speech_edit):\n",
    "    \"\"\"Remove stop words from string and return string.\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    speech_edit_no_stop = ''\n",
    "    for word in nltk.word_tokenize(speech_edit):\n",
    "        if word.lower() not in stop_words:\n",
    "            speech_edit_no_stop += word + ' '  \n",
    "    return speech_edit_no_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5469a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_freq(speech_edit_no_stop):\n",
    "    \"\"\"Return a dictionary of word frequency in a string.\"\"\"\n",
    "    word_freq = nltk.FreqDist(nltk.word_tokenize(speech_edit_no_stop.lower()))\n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96f7ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_sentences(speech, word_freq, max_words):\n",
    "    \"\"\"Return dictionary of sentence scores based on word frequency.\"\"\"\n",
    "    sent_scores = dict()\n",
    "    sentences = nltk.sent_tokenize(speech)\n",
    "    for sent in sentences:\n",
    "        sent_scores[sent] = 0\n",
    "        words = nltk.word_tokenize(sent.lower())\n",
    "        sent_word_count = len(words)\n",
    "        if sent_word_count <= int(max_words):\n",
    "            for word in words:\n",
    "                if word in word_freq.keys():\n",
    "                    sent_scores[sent] += word_freq[word]\n",
    "            sent_scores[sent] = sent_scores[sent] / sent_word_count\n",
    "    return sent_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f140354",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'conversations_customer_interaction.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-deba3ec7e12e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'conversations_customer_interaction.txt'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'conversations_customer_interaction.txt'"
     ]
    }
   ],
   "source": [
    "with open('conversations_customer_interaction.txt') as infile:\n",
    "    text = infile.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6d8304",
   "metadata": {},
   "source": [
    "I just want to see the 10 most important phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5369e6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request input.\n",
    "while True:\n",
    "    max_words = input(\"Enter max words per sentence for summary: \")\n",
    "    num_sents = input(\"Enter number of sentences for summary: \")\n",
    "    if max_words.isdigit() and num_sents.isdigit():\n",
    "        break\n",
    "    else:\n",
    "        print(\"\\nInput must be in whole numbers.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4668b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix typos, remove extra spaces, digits, and punctuation.\n",
    "feedback = re.sub('\\s+', ' ', feedback) \n",
    "feedback_edit = re.sub('[^a-zA-Z]', ' ', feedback)\n",
    "feedback_edit = re.sub('\\s+', ' ', feedback_edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d359f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_edit_no_stop = remove_stop_words(feedback_edit)\n",
    "word_freq = get_word_freq(feedback_edit_no_stop)\n",
    "sent_scores = score_sentences(feedback, word_freq, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e88560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the top-ranked sentences.\n",
    "counts = Counter(sent_scores)\n",
    "summary = counts.most_common(int(num_sents))\n",
    "print(\"\\nSUMMARY:\")\n",
    "for i in summary:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef842f2c",
   "metadata": {},
   "source": [
    "**End.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
